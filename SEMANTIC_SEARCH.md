# Semantic Search Feature

## Overview

Your VRM Fleet Dashboard now includes **semantic search** powered by Voyage AI embeddings and Claude AI. This enables you to search across your entire fleet using natural language queries and get AI-powered answers.

## Features

### üîç Two Search Modes

1. **Semantic Search** (Default)
   - Uses vector embeddings for intelligent similarity matching
   - Finds relevant trailers, devices, and alerts based on meaning, not just keywords
   - Examples:
     - "trailers offline" ‚Üí Finds all offline trailers
     - "weak signal" ‚Üí Finds devices with poor connectivity
     - "low battery" ‚Üí Finds sites with low battery SOC
     - "energy deficit" ‚Üí Finds alerts about power issues

2. **SQL Query Mode**
   - Natural language to SQL powered by Claude
   - Generates and executes database queries
   - Best for complex analytical questions
   - Examples:
     - "Which trailers have been offline for more than 2 days?"
     - "Show me average signal strength by carrier"
     - "What's the total data usage this week?"

### üìä What Gets Indexed

The semantic search indexes:
- **Sites**: Battery SOC, voltage, solar power, charge state, temperature
- **Devices**: Online/offline status, signal strength, carrier, technology
- **Alerts**: Energy deficit alerts, severity levels, affected sites

### ‚ö° Auto-Updates

Embeddings are automatically regenerated:
- Every 5 minutes during background polling
- After VRM and Pepwave data updates
- Includes real-time alerts and status changes

## Setup Instructions

### 1. Install PostgreSQL Extension

Enable the `pgvector` extension in your PostgreSQL database:

```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

**Note**: If using managed PostgreSQL (Railway, Supabase, etc.), pgvector is usually pre-installed.

### 2. Get Voyage AI API Key

1. Go to [https://dash.voyageai.com/](https://dash.voyageai.com/)
2. Sign up for a free account
3. Navigate to API Keys section
4. Create a new API key
5. Copy the key

### 3. Configure Environment Variables

Add to your `.env` file:

```bash
VOYAGE_API_KEY=your_voyage_api_key_here
```

Your `.env` should now have:
```bash
# Existing keys
VRM_API_TOKEN=...
ANTHROPIC_API_KEY=...
DATABASE_URL=...

# New: Voyage AI for semantic search
VOYAGE_API_KEY=your_voyage_api_key_here
```

### 4. Install Dependencies

Already done! The setup automatically installed:
- `voyageai` - Voyage AI SDK for embeddings
- `pg` with pgvector support

### 5. Start the Server

```bash
npm run dev
```

On startup, the server will:
1. Create the `fleet_embeddings` table
2. Create vector similarity indexes
3. Begin background embedding generation

### 6. Generate Initial Embeddings

After the server starts and data is polled, embeddings will be auto-generated. You can also manually trigger:

```bash
curl -X POST http://localhost:3001/api/embeddings/generate
```

Or use the API from your frontend.

## API Endpoints

### Semantic Search

**POST** `/api/search/semantic`

Request:
```json
{
  "query": "trailers with weak signal",
  "contentTypes": ["site", "device", "alert"],  // optional
  "limit": 20  // optional, default 20
}
```

Response:
```json
{
  "success": true,
  "query": "trailers with weak signal",
  "answer": "Found 5 devices with weak signal...",
  "results": [
    {
      "type": "device",
      "id": "Trailer-42",
      "text": "Device: Trailer-42, Online, Signal: 2/5 bars, RSRP: -110dBm...",
      "similarity": 0.89,
      "metadata": {
        "device_name": "Trailer-42",
        "signal_bar": 2,
        "online": true
      }
    }
  ],
  "count": 5
}
```

### Generate Embeddings

**POST** `/api/embeddings/generate`

Manually trigger embedding generation for all current data.

Response:
```json
{
  "success": true,
  "sites_embedded": 110,
  "devices_embedded": 110,
  "alerts_embedded": 3
}
```

### Embedding Statistics

**GET** `/api/embeddings/stats`

Get counts of embedded content by type.

Response:
```json
{
  "success": true,
  "stats": [
    { "content_type": "site", "count": 110, "latest_timestamp": 1709567890000 },
    { "content_type": "device", "count": 110, "latest_timestamp": 1709567891000 },
    { "content_type": "alert", "count": 3, "latest_timestamp": 1709567892000 }
  ]
}
```

## Database Schema

### fleet_embeddings Table

```sql
CREATE TABLE fleet_embeddings (
  id SERIAL PRIMARY KEY,
  content_type TEXT NOT NULL,      -- 'site', 'device', 'alert'
  content_id TEXT NOT NULL,        -- site_id, device_name, or alert_id
  content_text TEXT NOT NULL,      -- Searchable text representation
  embedding vector(1024),          -- 1024-dimensional Voyage-3 embedding
  metadata JSONB,                  -- Additional data for filtering
  timestamp BIGINT NOT NULL,       -- When embedding was created
  UNIQUE(content_type, content_id)
);

-- Vector similarity index (HNSW for fast search)
CREATE INDEX idx_fleet_embeddings_vector
  ON fleet_embeddings USING hnsw (embedding vector_cosine_ops);
```

## How It Works

### Embedding Generation

1. **Data Collection**: Latest snapshots are collected from cache
2. **Text Conversion**: Each item is converted to searchable text:
   - Site: "Site: Trailer-1, Battery: 85% SOC, 12.8V, Solar: 250W, State: Bulk"
   - Device: "Device: Trailer-1, Online, Signal: 4/5 bars, RSRP: -85dBm, Carrier: AT&T"
3. **Embedding**: Text is sent to Voyage AI API (voyage-3 model)
4. **Storage**: 1024-dim vector stored in PostgreSQL with metadata

### Search Process

1. **Query Embedding**: User query converted to vector
2. **Similarity Search**: pgvector finds closest matches using cosine distance
3. **Results Ranking**: Results sorted by similarity score
4. **AI Synthesis**: Claude generates natural language answer from top results

### Vector Search Performance

- HNSW index enables sub-second searches on 100,000+ embeddings
- Cosine similarity for semantic matching
- Results include similarity scores (0-1, higher = better match)

## Usage Examples

### Frontend (React)

```javascript
import { semanticSearch } from '../api/vrm'

const results = await semanticSearch('low battery trailers', ['site'], 10)
console.log(results.answer)
console.log(results.results)
```

### Search Query Ideas

**Site/Battery Queries:**
- "trailers with low battery"
- "sites in bulk charging"
- "high temperature batteries"
- "low solar output"

**Device/Network Queries:**
- "offline trailers"
- "weak cellular signal"
- "devices using 5G"
- "high data usage"

**Alert Queries:**
- "energy deficit"
- "critical alerts"
- "power problems"

## Cost Considerations

### Voyage AI Pricing

- **Free Tier**: 10M tokens/month (~500,000 embeddings)
- **Paid**: $0.12 per 1M tokens

For 110 trailers with 5-min updates:
- ~110 sites √ó 2 updates/hour √ó 24 hours = 5,280 embeddings/day
- Monthly: ~160,000 embeddings
- **Well within free tier!**

### Database Storage

Each embedding: ~4KB (1024 floats)
- 110 sites + 110 devices + alerts = ~1MB total
- Negligible storage cost

## Troubleshooting

### "Voyage API key not configured"

- Ensure `VOYAGE_API_KEY` is set in `.env`
- Restart the server after adding the key

### "Database not available"

- Check `DATABASE_URL` is configured
- Verify PostgreSQL is running
- Check pgvector extension is enabled

### "No results found"

- Wait for initial embeddings to generate (happens automatically after first data poll)
- Manually trigger: `POST /api/embeddings/generate`
- Check embedding stats: `GET /api/embeddings/stats`

### Slow search performance

- Ensure HNSW index is created
- Check database connection
- Consider reducing `limit` parameter

## Advanced Configuration

### Custom Embedding Model

Edit `server/embeddings.js`:

```javascript
const EMBEDDING_MODEL = 'voyage-3';  // or 'voyage-2', etc.
```

### Adjust Update Frequency

Edit `server/server.js`:

```javascript
// Change from 5 minutes to 10 minutes
setInterval(pollAllSites, 10 * 60 * 1000);
```

### Content Type Filtering

Search only specific types:

```javascript
await semanticSearch('query', ['device'], 20)  // Only devices
await semanticSearch('query', ['site', 'alert'], 20)  // Sites and alerts
```

## Performance Metrics

On a typical setup (110 trailers):

- **Embedding generation**: ~2-3 seconds for all trailers
- **Search query**: <100ms
- **Background updates**: ~5 seconds total (includes data polling)
- **Memory usage**: +50MB for embeddings cache

## Future Enhancements

Possible additions:
- Historical event indexing (alarms, diagnostics)
- Multi-language support
- Custom similarity thresholds
- Embedding-based anomaly detection
- Automatic clustering of similar issues

## Support

For issues or questions:
- Check server logs for embedding generation errors
- Verify API keys are valid
- Test with simple queries first
- Check `/api/embeddings/stats` for index status
